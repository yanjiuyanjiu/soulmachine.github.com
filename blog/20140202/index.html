
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>在CentOS上安装Hadoop集群 - 研究研究</title>
  <meta name="author" content="soulmachine">

  
  <meta name="description" content="一个关于机器学习的技术博客">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://www.yanjiuyanjiu.com/blog/20140202">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/bootstrap/bootstrap.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/bootstrap/responsive.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/syntax/syntax.css" media="screen, projection" rel="stylesheet" type="text/css">
  <style type="text/css">
    body {
      padding-bottom: 40px;
    }
    h1 {
      margin-bottom: 15px;
    }
    img {
      max-width: 100%;
    }
    .sharing, .meta, .pager {
      margin: 20px 0px 20px 0px;
    }
    .page-footer p {
      text-align: center;
    }
  </style>
  <script src="/javascripts/libs/jquery.js"></script>
  <script src="/javascripts/libs/modernizr-2.0.js"></script>
  <script src="/javascripts/libs/bootstrap.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="研究研究" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<!-- <link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css"> -->
<!-- <link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css"> -->

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-7583537-4']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <nav role="navigation"><div class="navbar navbar-inverse">
  <div class="navbar-inner">
    <div class="container">
      <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </a>

      <a class="brand" href="/">研究研究</a>

      <div class="nav-collapse">
        <ul class="nav">
  <li><a href="/">Home</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about/">About</a></li>
  <li><a href="/notes/">读书笔记</a></li>
</ul>


        <ul class="nav pull-right" data-subscription="rss">
          <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
          
        </ul>

        
          <form class="pull-right navbar-search" action="http://google.com/search" method="get">
            <fieldset role="search">
              <input type="hidden" name="q" value="site:www.yanjiuyanjiu.com" />
              <input class="search-query" type="text" name="q" results="0" placeholder="Search"/>
            </fieldset>
          </form>
        
      </div>
    </div>
  </div>
</div>
</nav>
  <div class="container">
    <div class="row-fluid">
      
<article class="hentry span9" role="article">

  
  <header class="page-header">
    
      <h1 class="entry-title">在CentOS上安装Hadoop集群</h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-02-02T12:39:00+08:00" pubdate data-updated="true">Feb 2<span>nd</span>, 2014</time>
        
		
         | <a href="#duoshuo_thread">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><p>Ubuntu上安装，请参考我的另一篇博客，<a href="http://www.yanjiuyanjiu.com/blog/20120103/">在Ubuntu上安装Hadoop</a>。</p>

<p><strong>环境</strong>：CentOS 6.5, OPenJDK 1.7, Hadoop 1.2.1</p>

<p>本文主要参考官网的文档，<a href="http://hadoop.apache.org/docs/r1.2.1/#Getting+Started">Hadoop 1.2.1 Getting Started</a></p>

<h2 id="standalone-mode">1 单机模式(Standalone Mode)</h2>
<p>为了能顺利安装成功，我们先练习在单台机器上安装Hadoop。在单台机器上，可以配置成单机模式(Standalone Mode)和伪分布式模式(Pseudo-Distributed Mode)，参考官方文档<a href="http://hadoop.apache.org/docs/r1.2.1/single_node_setup.html">Single Node Setup</a>。</p>

<h3 id="hadoop-121">1.1 下载Hadoop 1.2.1，解压</h3>
<p>用浏览器下载或wget,</p>

<pre><code>$ wget http://mirror.olnevhost.net/pub/apache/hadoop/common/stable1/hadoop-1.2.1-bin.tar.gz
$ tar -zxf hadoop-1.2.1-bin.tar.gz -C ~/local/opt
$ cd ~/local/opt/hadoop-1.2.1
</code></pre>

<h3 id="confhadoop-envsh-javahome">1.2 编辑 conf/hadoop-env.sh，设置 <code>JAVA_HOME</code></h3>

<pre><code>$ echo $JAVA_HOME
/usr/lib/jvm/java
$ vim conf/hadoop-env.sh
</code></pre>

<p>取消<code>JAVA_HOME</code>那一行的注释，设置正确的JDK位置</p>

<pre><code>export JAVA_HOME=/usr/lib/jvm/java
</code></pre>

<h3 id="job">1.3 运行一个job</h3>
<p>默认情况下，Hadoop就被配置为Standalone模式了，此时Hadoop的所有模块都运行在一个java进程里。</p>

<p>我们运行一个例子测试一下。下面的几行命令，把 <code>conf</code>下的所有xml文件作为输入，在文件中查找指定的正则表达式，把匹配的结果输出到<code>output</code>目录。</p>

<pre><code>$ mkdir input 
$ cp conf/*.xml input 
$ bin/hadoop jar hadoop-examples-*.jar grep input output 'dfs[a-z.]+' 
$ cat output/*
</code></pre>

<p>可以看到正常的结果，说明单机模式运行成功了，下面开始配置伪分布式模式。</p>

<!-- more -->

<h2 id="pseudo-distributed-mode">2 伪分布式模式(Pseudo-Distributed Mode)</h2>
<p>Hadoop能在单台机器上以伪分布式模式运行，即每个Hadoop模块运行在单独的java进程里。</p>

<h3 id="confhadoop-envsh-javahome-1">2.1 编辑 conf/hadoop-env.sh，设置 <code>JAVA_HOME</code></h3>

<pre><code>$ echo $JAVA_HOME
/usr/lib/jvm/java
$ vim conf/hadoop-env.sh
</code></pre>

<h3 id="ssh">2.2 设置无密码SSH登录</h3>
<p>先检查一下是能够无密码登录本机，</p>

<pre><code>ssh localhost
</code></pre>

<p>如果提示输入密码，说明不能，按如下步骤设置。</p>

<pre><code>$ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa 
$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
</code></pre>

<h3 id="section">2.3 配置</h3>

<p>conf/core-site.xml:</p>

<pre><code>&lt;configuration&gt;
     &lt;property&gt;
         &lt;name&gt;fs.default.name&lt;/name&gt;
         &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
     &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>conf/hdfs-site.xml:</p>

<pre><code>&lt;configuration&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.replication&lt;/name&gt;
         &lt;value&gt;1&lt;/value&gt;
     &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>conf/mapred-site.xml:</p>

<pre><code>&lt;configuration&gt;
     &lt;property&gt;
         &lt;name&gt;mapred.job.tracker&lt;/name&gt;
         &lt;value&gt;localhost:9001&lt;/value&gt;
     &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<h3 id="hadoop">2.4 启动Hadoop</h3>

<p>格式化namenode</p>

<pre><code>$ bin/hadoop namenode -format
</code></pre>

<p>启动 Hadoop 后台进程</p>

<pre><code>$ bin/start-all.sh
</code></pre>

<p>Hadoop的log写入到了<code>${HADOOP_HOME}/logs</code>目录下。</p>

<p>现在可以用浏览器打开NameNode和JobTracker的web界面了。</p>

<ul>
  <li>NameNode - <a href="http://localhost:50070/">http://localhost:50070/</a></li>
  <li>JobTracker - <a href="http://localhost:50030/">http://localhost:50030/</a></li>
</ul>

<h3 id="section-1">2.5 运行一个例子</h3>
<p>运行的例子跟单机模式下的例子相同。</p>

<p>将输入数据拷贝到分布式文件系统中:</p>

<pre><code>$ bin/hadoop fs -put conf input
</code></pre>

<p>运行 Hadoop 自带的例子:</p>

<pre><code>$ bin/hadoop jar hadoop-examples-*.jar grep input output 'dfs[a-z.]+'
</code></pre>

<p>查看输出文件:</p>

<pre><code>$ bin/hadoop fs -cat output/*

1	dfs.replication
1	dfs.server.namenode.
1	dfsadmin
</code></pre>

<p>结束后，关闭 Hadoop:</p>

<pre><code>$ bin/stop-all.sh

stopping jobtracker
localhost: stopping tasktracker
stopping namenode
localhost: stopping datanode
localhost: stopping secondarynamenode
</code></pre>

<h2 id="fully-distributed-mode">3 分布式模式(Fully-Distributed Mode)</h2>
<p>主要参考官方文档<a href="http://hadoop.apache.org/docs/r1.2.1/cluster_setup.html">Cluster Setup</a>.</p>

<h3 id="section-2">3.1 准备3台机器</h3>
<p>如果你已经有了三台机器，这一步可以省略。</p>

<p>如果没有，则可以用VMware Workstation 或 VirtualBox创建3台虚拟机。首先用vmware workstation 新建一台CentOS 6.5，装好操作系统，选择 Basic Server，安装JDK，参考我的另一篇博客，<a href="http://www.yanjiuyanjiu.com/blog/20120423/">安装和配置CentOS服务器的详细步骤</a>。安装好后然后用<strong>浅拷贝</strong><code>Create a linked clone</code> 克隆出2台，这样有了3台虚拟机。启动3台机器，假设IP分别为<code>192.168.1.131, 192.168.1.132, 192.168.1.133</code>, 131做为NameNode,JobTracker和SecondaryNameNode，身兼3个角色，这3个角色应该放到3台不同的机器上，这里为了简化，用一台机器来做3个角色；132和133为 slave。三台机器上的用户名是<code>hadoop</code>，也可以用其他用户名，但必须三台机器都相同。</p>

<h4 id="section-3">3.1.1 关闭防火墙</h4>
<p>临时关闭防火墙</p>

<pre><code>$ sudo service iptables stop
</code></pre>

<p>下次开机后，防火墙还是会启动。</p>

<p>永久关闭防火墙</p>

<pre><code>$ sudo chkconfig iptables off
</code></pre>

<p>由于这几台虚拟机是开发机，不是生产环境，因此不必考虑安全性，可以永久关闭防火墙，还能给开发阶段带来很多便利。</p>

<h4 id="hostname">3.1.2 修改hostname</h4>
<p>如果集群中的每一台机器事先已经有了hostname，则这一步可以跳过。</p>

<p>这一步看起来貌似不必要，其实是必须的，否则最后运行wordcount等例子时，会出现“Too many fetch-failures”。因为HDFS用hostname而不是IP，来相互之间进行通信（见后面的注意1）。</p>

<p>在CentOS上修改hostname，包含两个步骤(假设将hostname1改为hostname2，参考<a href="http://www.ichiayi.com/wiki/tech/linux_hostname">这里</a>，但不需要第一步)：</p>

<ol>
  <li>将 <code>/etc/sysconfig/network</code> 內的 HOSTNAME 改成 yourhostname</li>
  <li>用<code>hostname</code>命令，临时修改机器名， <code>sudo hostname yourhostname</code></li>
</ol>

<p>用<code>exit</code>命令退出shell，再次登录，命令提示字符串就会变成<code>[username@yourhostname ~]$</code>。</p>

<p>用上述方法，将131改名为master，132改名为slave01，133改名为slave02。</p>

<p><strong>注意</strong>，对于有的Ubuntu/Debia 系统，会把本机的hostname解析成 127.0.1.1，例如：</p>

<pre><code>127.0.0.1       localhost
127.0.1.1       master
</code></pre>

<p>将第二行改为(参考<a href="http://wiki.ubuntu.org.cn/%E5%88%A9%E7%94%A8Cloudera%E5%AE%9E%E7%8E%B0Hadoop">利用Cloudera实现Hadoop</a>)</p>

<pre><code>127.0.0.1       master
</code></pre>

<h4 id="etchosts">3.1.3 修改所有机器的<code>/etc/hosts</code>文件</h4>
<p>在所有机器的<code>/etc/hosts</code>文件中，添加所有hostname对应的IP，一般在一台机器上设置好，然后scp到所有机器。例如</p>

<pre><code>192.168.1.131 master
192.168.1.132 slave01
192.168.1.133 slave02
</code></pre>

<h2 id="master-master">3.2 配置 master 无密码登陆到所有机器（包括master自己登陆自己）</h2>
<p>参考我的另一篇博客，<a href="http://www.yanjiuyanjiu.com/blog/20120102/">SSH无密码登录的配置</a></p>

<h2 id="hadoop-1">3.3 把Hadoop压缩包上传到所有机器，并解压</h2>
<p>将 hadoop-1.2.1-bin.tar.gz 上传到所有机器，然后解压。<strong>注意，所有机器的hadoop路径必须一致，因为master会登陆到slave上执行命令，master认为slave的hadoop路径与自己一样。</strong></p>

<p>下面开始配置，配置好了后，把conf 目录scp到所有其他机器。</p>

<h3 id="section-4">3.4 修改6个配置文件</h3>
<p>Hadoop的配置文件比较多，其设计原则可以概括为如下两点：</p>

<ul>
  <li>尽可能模块化。例如core-xxx.xml是针对基础公共库core的，hdfs-xxx.xml是针对分布式文件系统HDFS的，mapred-xxx.xml是针对分布式计算框架MapReduce的。</li>
  <li>动静分离。例如，在Hadoop 1.0.0之前，作业队列权限管理相关的配置被放在mapred-site.xml里，而该文件爱你是不可以动态加载的，每次修改后必须重启Hadoop，但从 1.0.0后，这些配置选项被剥离出来放到独立的配置文件mapred-queue-acls.xml中，该文件可以通过Hadoop命令动态加载。在conf下，core-default.xml, hdfs-default.xml和mapred-default.xml是只读的，core-site.xml, hdfs-site.xml和mapred-site.xml才是用户可以修改的。要想覆盖默认配置，就在xxx-site.xml里修改。</li>
</ul>

<p>以下操作在master上进行。</p>

<h3 id="confhadoop-envsh">3.4.1 conf/hadoop-env.sh</h3>
<p>在 conf/hadoop-env.sh里，设置 <code>JAVA_HOME</code>。如果集群中，每台机器的JDK不一定统一安装在同一个路径，那就要在每个节点的hadoop-env.sh里分别设置<code>JAVA_HOME</code>。</p>

<pre><code>export JAVA_HOME=/usr/lib/jvm/java
</code></pre>

<p>还要设置<code>HADOOP_PID_DIR</code>，这里我们令其为<code>HADOOP_PID_DIR=/home/hadoop/local/var/hadoop/pids</code>，参考<a href="http://www.iteye.com/topic/299219">Hadoop的pid配置</a>。</p>

<pre><code>export HADOOP_PID_DIR=/home/hadoop/local/var/hadoop/pids
</code></pre>

<p>注意，还要<strong>禁用IPv6</strong>，用命令<code>cat /proc/sys/net/ipv6/conf/all/disable_ipv6</code>检查一下系统是否启用了IPv6，如果是0,说明启用了。Hadoop在IPv6的情况下运行不正常，因此需禁用IPv6。</p>

<p>不过我们不用真的禁用IPv6，还有另外一种方法，让java优先选择IPv4即可，在conf/hadoop-env.sh 里添加如下一行，</p>

<pre><code>export HADOOP_OPTS="-server -Djava.net.preferIPv4Stack=true $HADOOP_OPTS"
</code></pre>

<p>参考<a href="http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-single-node-cluster/#disabling-ipv6">Disabling IPv6</a>，以及Web Crawling and Data Mining with Apache Nutch这本书的第66页。</p>

<h3 id="confmasters">3.4.2 conf/masters</h3>

<pre><code>master
</code></pre>

<h3 id="confslaves">3.4.3 conf/slaves</h3>

<pre><code>slave01
slave02
</code></pre>

<p>这里解释一下，masters文件，存放的其实是SecondaryNameNode。关于masters和slaves两个配置文件，更精确的说明见这个StackOverflow答案，<a href="http://stackoverflow.com/a/19779590/381712">hadoop conf/masters and conf/slaves on jobtracker?</a></p>

<h3 id="confcore-sitexml">3.4.4 conf/core-site.xml</h3>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.default.name&lt;/name&gt;
        &lt;value&gt;hdfs://master:9000&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;fs.checkpoint.dir&lt;/name&gt;
        &lt;value&gt;/home/hadoop/local/var/hadoop/dfs/namesecondary&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>Hadoop会自动创建目录。</p>

<h3 id="confhdfs-sitexml">3.4.5 conf/hdfs-site.xml</h3>

<pre><code>&lt;configuration&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.name.dir&lt;/name&gt;
         &lt;value&gt;/home/hadoop/local/var/hadoop/dfs/name&lt;/value&gt;
     &lt;/property&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.data.dir&lt;/name&gt;
         &lt;value&gt;/home/hadoop/local/var/hadoop/dfs/data&lt;/value&gt;
     &lt;/property&gt;
     &lt;property&gt;
       &lt;name&gt;dfs.replication&lt;/name&gt;
       &lt;value&gt;2&lt;/value&gt;
     &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>我们只有2台slave，因此<code>dfs.replication</code>设置为2。</p>

<p>Hadoop会自动在master创建 /home/hadoop/local/var/hadoop/dfs/name 目录，在 slaves上创建 /home/hadoop/local/var/hadoop/dfs/data 目录。</p>

<h3 id="confmapred-sitexml">3.4.6 conf/mapred-site.xml</h3>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapred.job.tracker&lt;/name&gt;
        &lt;value&gt;master:9001&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapred.local.dir&lt;/name&gt;
        &lt;value&gt;/home/hadoop/local/var/hadoop/mapred/local&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobtracker.staging.root.dir&lt;/name&gt;
        &lt;value&gt;/user&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<h3 id="slaves">3.5 将配置文件拷贝到所有slaves</h3>

<pre><code>$ cd ~/local/opt/hadoop-1.2.1/conf/
$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves hadoop@slave01:~/local/opt/hadoop-1.2.1/conf/
$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves hadoop@slave02:~/local/opt/hadoop-1.2.1/conf/
</code></pre>

<h3 id="hadoop-2">3.6 运行 hadoop</h3>
<p>在master上执行以下命令，启动hadoop</p>

<pre><code>$ cd ~/local/opt/hadoop-1.2.1/
#只需一次，下次启动不再需要格式化，只需 start-all.sh
$ bin/hadoop namenode -format
$ bin/start-all.sh
</code></pre>

<h3 id="section-5">3.7 检查是否启动成功</h3>

<p>在master上执行：</p>

<pre><code>$ jps

2615 NameNode
2767 JobTracker
2874 Jps
</code></pre>

<p>在一台slave上执行：</p>

<pre><code>$ jps

3415 DataNode
3582 TaskTracker
3499 SecondaryNameNode
3619 Jps
</code></pre>

<p>在另一台slave上执行：</p>

<pre><code>$ jps

3741 Jps
3618 DataNode
3702 TaskTracker
</code></pre>

<p>可见进程都启动起来了，说明hadoop运行成功。</p>

<h3 id="wordcount">3.8 运行wordcount例子，进一步测试是否安装成功</h3>
<p>将输入数据拷贝到分布式文件系统中:</p>

<pre><code>$ cd ~/local/opt/hadoop-1.2.1/
$ bin/hadoop fs -put conf input
</code></pre>

<p>运行 Hadoop 自带的例子:</p>

<pre><code>$ bin/hadoop jar hadoop-examples-*.jar wordcount input output
</code></pre>

<p>查看输出文件:</p>

<pre><code>$ bin/hadoop fs -ls output
$ bin/hadoop fs -cat output/part-r-00000
</code></pre>

<p>如果能看到结果，说明这个例子运行成功。</p>

<h3 id="hadoop-3">3.9 停止 hadoop集群</h3>
<p>在master上执行：</p>

<pre><code>$ bin/stop-all.sh
</code></pre>

<h3 id="masterhadoopprefixhadoopprefixbinpath">3.10 （可选）在master上设置环境变量HADOOP_PREFIX，并将HADOOP_PREFIX/bin加入PATH</h3>
<p>这一步是为了将bin目录加入PATH，这样可以在任何位置执行hadoop的各种命令。这步是可选的。</p>

<p>Hadoop不推荐使用<code>HADOOP_HOME</code>，你可以试一下，当设置了<code>HADOOP_HOME</code>后，执行<code>bin/start-all.sh</code>，第一行会打印出一行警告信息，<code>Warning: $HADOOP_HOME is deprecated.</code> 应该用<code>HADOOP_PREFIX</code>代替，见邮件列表里的这封<a href="http://mail-archives.apache.org/mod_mbox/hadoop-common-user/201202.mbox/%3CCB4ECC21.33727%25evans@yahoo-inc.com%3E">邮件</a>。</p>

<p>给所有机器设置环境变量<code>HADOOP_PREFIX</code>，并将<code>$HADOOP_PREFIX/bin</code>加入PATH。</p>

<p>在 <code>~/.bashrc</code>中添加如下4行：</p>

<pre><code>export HADOOP_PREFIX=$HOME/local/opt/hadoop-1.2.1
export PATH=$PATH:$HADOOP_PREFIX/bin
</code></pre>

<p>source使之立刻生效，</p>

<pre><code>$ source ~/.bashrc
</code></pre>

<h2 id="section-6">4. 排除错误</h2>
<p>本文已经尽可能的把步骤详细列出来了，但是我相信大部分人不会一次成功。这时候，查找错误就很重要了。查找错误最重要的手段是查看hadoop的日志，一般在logs目录下。把错误消息复制粘贴到google，搜索一下，慢慢找错误。</p>

<h2 id="section-7">注意</h2>
<ol>
  <li>所有配置文件只能用hostname，不能用IP。两年前我不懂，还为此<a href="http://stackoverflow.com/questions/8702637/hadoop-conf-fs-default-name-cant-be-setted-ipport-format-directly">在stackoverflow上发了帖子</a>。hadoop会反向解析hostname，即使是用了IP，也会使用hostname 来启动TaskTracker。参考<a href="http://stackoverflow.com/questions/15230946/hdfs-lan-ip-address-hostname-resolution">hdfs LAN ip address hostname resolution</a>，<a href="http://www.makenotes.net/?p=337004">hadoop入门经验总结- 杨贵堂的博客</a>，<a href="http://51mst.iteye.com/blog/1152439">hadoop集群配置</a>。</li>
  <li>在第2.5步骤，如果出现 <code>SafeModeException</code> 异常，不用担心，等待几分钟即可。因为hadoop刚刚启动时，会进入安全模式进行自检，这需要花点时间。</li>
  <li>如果在任何一步失败，可以<code>stop-all.sh</code>, 然后<code>hadoop  namenode -format</code>，重试几次，一般可以成功。如果还是不成功，多看看 logs目录下的日志文件，把错误消息复制粘贴到google，搜索答案。</li>
</ol>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">soulmachine</span></span>

      








  


<time datetime="2014-02-02T12:39:00+08:00" pubdate data-updated="true">Feb 2<span>nd</span>, 2014</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/hadoop/'>Hadoop</a>
  
</span>


    </p>
    
      <div class="sharing">
  <!-- AddThis Button BEGIN -->
  <div class="addthis_toolbox addthis_default_style addthis_32x32_style">
    <a class="addthis_button_sinaweibo"></a>
    <a class="addthis_button_facebook"></a>
    <a class="addthis_button_twitter"></a>
    <a class="addthis_button_google_plusone_share"></a>
    <a class="addthis_button_delicious"></a>
    <a class="addthis_button_digg"></a>
    <a class="addthis_button_reddit"></a>
    <a class="addthis_button_compact"></a><a class="addthis_counter addthis_bubble_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=undefined"></script>
  <!-- AddThis Button END -->
  
  
  
</div>

    
    
	
    <section>
      <div id="duoshuo_thread" aria-live="polite"><!-- Duoshuo Comment BEGIN -->
<div class="ds-thread" data-thread-key="/blog/20140202" data-title="在CentOS上安装Hadoop集群"></div>
<script type="text/javascript">
var duoshuoQuery = {short_name:"yanjiuyanjiu"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = 'http://static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		|| document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
</script>
<!-- Duoshuo Comment END --></div>
    </section>
    
    <ul class="pager">
      
      <li class="previous"><a class="basic-alignment left"
        href="/blog/20140201" title="Previous Post:
        Nutch 快速入门(Nutch 2.2.1)">&laquo; Nutch 快速入门(Nutch 2.2.1)</a></li>
      
      <li><a href="/blog/archives">Blog Archives</a></li>
      
      <li class="next"><a class="basic-alignment right" href="/blog/20140203"
        title="Next Post: Hadoop多用户的配置(Hadoop 1.x)">Hadoop多用户的配置(Hadoop 1.x)
        &raquo;</a></li>
      
    </ul>
  </footer>
</article>

<aside class="sidebar-nav span3">
  
    <section>
  <h2>公告</h2>
  <p>独学而无友，则孤陋而寡闻，我每周在清华举办机器学习读书会，欢迎大家前来交流切磋。</p>
  <p>详情请见<a href="http://q.weibo.com/1644133">读书会微博群</a></p>
</section>
<section>
  <h2>分类目录</h2>
    <ul id="category-list"><li><a href='/blog/categories/algorithm/'>Algorithm (1)</a></li><li><a href='/blog/categories/devops/'>DevOps (8)</a></li><li><a href='/blog/categories/docker/'>Docker (3)</a></li><li><a href='/blog/categories/hadoop/'>Hadoop (8)</a></li><li><a href='/blog/categories/language/'>Language (3)</a></li><li><a href='/blog/categories/machine-learning/'>Machine-Learning (5)</a></li><li><a href='/blog/categories/search-engine/'>Search-Engine (5)</a></li><li><a href='/blog/categories/spark/'>Spark (6)</a></li><li><a href='/blog/categories/tools/'>Tools (11)</a></li></ul>
</section>
<section>
  <h2>友情链接</h2>
  <ul>
    <li>
      <a href="http://yewen.us/" title="大学同学，ACM高手，曾在百度，现在人人网">笨狗随手留下</a>
    </li>
	<li>
      <a href="http://blog.liancheng.info/" title="网易，百度，技术高手">连城</a>
    </li>
    <li>
      <a href="http://www.rational.so/" title="系统方向的清华博士">阎栋</a>
    </li>
	<li>
      <a href="http://www.parallellabs.com/" title="冠诚，IBM研究院研究员">并行实验室</a>
    </li>
	<li>
      <a href="http://blog.javachen.com/" title="">JavaChen</a>
    </li>
	<li>
      <a href="http://shenfeng.me/" title="http-kit, clojure">沈峰</a>
    </li>
	<li>
      <a href="http://www.lihaipeng.info/" title="百度商业产品高级研发工程师">李海鹏</a>
    </li>
	<li>
      <a href="http://www.chioka.in/" title="Google工程师">Eric</a>
    </li>
    <li>
      <a href="http://blog.csdn.net/lgnlgn" title="好朋友，曾在赶集网，现在老家的猫扑">梁兄的技术博客</a>
    </li>
    <li>
      <a href="http://www.doesbetter.com/" title="机器学习，北邮">王孝舒的博客</a>
    </li>
    <li>
      <a href="http://www.foreverlee.net/" title="机器学习，中科院计算所">ForeverLee</a>
    </li>
  </ul>
</section>




<section>
  <h2>最新文章</h2>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/20140220">编写Nutch插件</a>
      </li>
    
      <li class="post">
        <a href="/blog/20140214">CentOS上编译 Hadoop 2.2.0</a>
      </li>
    
      <li class="post">
        <a href="/blog/20140208">在CentOS上安装HBase 0.96</a>
      </li>
    
      <li class="post">
        <a href="/blog/20140207">在CentOS上安装ZooKeeper集群</a>
      </li>
    
      <li class="post">
        <a href="/blog/20140206">Hadoop多用户的配置(Hadoop 2.x)</a>
      </li>
    
  </ul>
</section><section>
<h2>最新评论</h2>
<ul class="ds-recent-comments" data-num-items="5" data-show-avatars="1" data-show-time="1" data-show-title="1" data-show-admin="0" data-excerpt-length="32"></ul>

</section>

  
</aside>


    </div>
  </div>
  <footer role="contentinfo" class="page-footer"><!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
<p>
  Copyright &copy; 2014 - soulmachine -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  











</body>
</html>
