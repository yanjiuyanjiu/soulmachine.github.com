
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>在CentOS上安装Hadoop 2.x 集群 - 研究研究</title>
  <meta name="author" content="soulmachine">

  
  <meta name="description" content="一个关于机器学习的技术博客">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://www.yanjiuyanjiu.com/blog/20140205">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/bootstrap/bootstrap.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/bootstrap/responsive.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/syntax/syntax.css" media="screen, projection" rel="stylesheet" type="text/css">
  <style type="text/css">
    body {
      padding-bottom: 40px;
    }
    h1 {
      margin-bottom: 15px;
    }
    img {
      max-width: 100%;
    }
    .sharing, .meta, .pager {
      margin: 20px 0px 20px 0px;
    }
    .page-footer p {
      text-align: center;
    }
  </style>
  <script src="/javascripts/libs/jquery.js"></script>
  <script src="/javascripts/libs/modernizr-2.0.js"></script>
  <script src="/javascripts/libs/bootstrap.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="研究研究" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<!-- <link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css"> -->
<!-- <link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css"> -->

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-7583537-4']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <nav role="navigation"><div class="navbar navbar-inverse">
  <div class="navbar-inner">
    <div class="container">
      <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </a>

      <a class="brand" href="/">研究研究</a>

      <div class="nav-collapse">
        <ul class="nav">
  <li><a href="/">Home</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about/">About</a></li>
  <li><a href="/notes/">读书笔记</a></li>
</ul>


        <ul class="nav pull-right" data-subscription="rss">
          <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
          
        </ul>

        
          <form class="pull-right navbar-search" action="http://google.com/search" method="get">
            <fieldset role="search">
              <input type="hidden" name="q" value="site:www.yanjiuyanjiu.com" />
              <input class="search-query" type="text" name="q" results="0" placeholder="Search"/>
            </fieldset>
          </form>
        
      </div>
    </div>
  </div>
</div>
</nav>
  <div class="container">
    <div class="row-fluid">
      
<article class="hentry span9" role="article">

  
  <header class="page-header">
    
      <h1 class="entry-title">在CentOS上安装Hadoop 2.x 集群</h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-02-05T12:39:00+08:00" pubdate data-updated="true">Feb 5<span>th</span>, 2014</time>
        
		
         | <a href="#duoshuo_thread">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><p><strong>环境</strong>：CentOS 6.5, OPenJDK 1.7, Hadoop 2.2.0</p>

<p>本文主要参考官网的文档，<a href="http://hadoop.apache.org/docs/r2.2.0/hadoop-project-dist/hadoop-common/SingleCluster.html">Hadoop 2.2.0 Single Node Setup</a>， <a href="http://hadoop.apache.org/docs/r2.2.0/hadoop-project-dist/hadoop-common/ClusterSetup.html">Hadoop 2.2.0  Cluster Setup</a></p>

<h2 id="section">（可选）创建新用户</h2>
<p>一般我倾向于把需要启动daemon进程，对外提供服务的程序，简单的说，就是服务器类程序，安装在单独的用户下面。这样可以做到隔离，运维方面，安全性也提高了。</p>

<p>创建一个新的group,</p>

<pre><code>$ sudo groupadd hadoop
</code></pre>

<p>创建一个新的用户，并加入group,</p>

<pre><code>$ sudo useradd -g hadoop hadoop
</code></pre>

<p>给新用户设置密码，</p>

<pre><code>$ sudo passwd hadoop
</code></pre>

<h2 id="pseudo-distributed-mode">1 伪分布式模式(Pseudo-Distributed Mode)</h2>
<p>Hadoop能在单台机器上以伪分布式模式运行，即每个Hadoop模块运行在单独的java进程里。</p>

<h3 id="sshlocalhost">1.1 设置SSH无密码登录localhost</h3>
<p>先检查一下是能够无密码登录本机，</p>

<pre><code>ssh localhost
</code></pre>

<p>如果提示输入密码，说明不能，按如下步骤设置。</p>

<pre><code>$ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa 
$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
</code></pre>

<h3 id="section-1">1.2 下载已经编译好的二进制包，解压</h3>
<p>用浏览器下载或wget,</p>

<pre><code>$ wget http://mirrors.hust.edu.cn/apache/hadoop/common/hadoop-2.2.0/hadoop-2.2.0.tar.gz
$ tar -zxf hadoop-2.2.0.tar.gz -C ~/local/opt
$ cd ~/local/opt/hadoop-2.2.0
</code></pre>

<h3 id="section-2">1.3 设置环境变量</h3>

<pre><code>$ vim ~/.bashrc
export HADOOP_PREFIX=$HOME/local/opt/hadoop-2.2.0
export HADOOP_COMMON_HOME=$HADOOP_PREFIX
export HADOOP_HDFS_HOME=$HADOOP_PREFIX
export HADOOP_MAPRED_HOME=$HADOOP_PREFIX
export HADOOP_YARN_HOME=$HADOOP_PREFIX
export HADOOP_CONF_DIR=$HADOOP_PREFIX/etc/hadoop
export PATH=$PATH:$HADOOP_PREFIX/bin:$HADOOP_PREFIX/sbin
</code></pre>

<!-- more -->

<h3 id="section-3">1.4 修改配置文件</h3>
<p>配置文件的位置在 <code>$HADOOP_PREIFIX/etc/hadoop</code>下面。</p>

<h3 id="hadoop-envsh">1.4.1 hadoop-env.sh</h3>
<p>在这个文件中要告诉hadoop JDK 安装在了哪里</p>

<pre><code>$ echo $JAVA_HOME
/usr/lib/jvm/java
$ vim conf/hadoop-env.sh
</code></pre>

<p>取消<code>JAVA_HOME</code>那一行的注释，设置正确的JDK位置</p>

<pre><code>export JAVA_HOME=/usr/lib/jvm/java
</code></pre>

<h4 id="hdfs">1.4.2 HDFS的配置</h4>
<p>为了简单，我们仍采用Hadoop 1.x中的HDFS工作模式（不配置HDFS Federation）。</p>

<p>core-site.xml:</p>

<pre><code>&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;fs.defaultFS&lt;/name&gt;
    &lt;value&gt;hdfs://localhost&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>hdfs-site.xml:</p>

<pre><code>&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
    &lt;value&gt;file:///home/hadoop/local/var/hadoop/hdfs/datanode&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
    &lt;value&gt;file:///home/hadoop/local/var/hadoop/hdfs/namenode&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.checkpoint.dir&lt;/name&gt;
    &lt;value&gt;file:///home/hadoop/local/var/hadoop/hdfs/namesecondary&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;1&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>Hadoop会自动创建目录。</p>

<h4 id="yarn">1.4.3 YARN的配置</h4>
<p>yarn-site.xml，不用修改，保持为空。</p>

<h4 id="mapreduce">1.4.4 MapReduce的配置</h4>
<p>Yarn不仅仅只支持MapReduce这种计算模式，还支持Spar, Tez, MPI等框架，因此，要显式地配置Yarn，使其支持mapreduce。在Hadoop 1.x中，只支持MapReduce，因此需要而且必须配置mapred-site.xml，到了Hadoop 2.x，MapReduce的配置是可选的。</p>

<p>在yarn-site.xml中添加：</p>

<pre><code>&lt;property&gt;
   &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
   &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p><strong>解释</strong>：为了能够运行MapReduce程序，需要让各个NodeManager在启动时加载shuffle server，shuffle server实际上是Jetty/Netty Server，Reduce Task通过该server从各个NodeManager上远程拷贝Map Task产生的中间结果。上面增加的这个配置用于指定shuffle server。</p>

<p>将 mapred-site.xml.template 复制一份，重命名为mapred-site.xml。</p>

<p>mapred-site.xml:</p>

<pre><code>&lt;property&gt;
   &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
   &lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p><strong>解释</strong>：用mapreduce.framework.name指定采用的框架名称，默认是将作业提交到MRv1的JobTracker端。</p>

<h3 id="section-4">1.5 测试</h3>

<h4 id="hdfs-1">1.5.1 启动HDFS</h4>

<pre><code>$ hdfs namenode -format
$ start-dfs.sh
</code></pre>

<h4 id="yarn-1">1.5.2 启动Yarn</h4>

<pre><code>$ start-yarn.sh
</code></pre>

<h4 id="mapreduce-1">1.5.3 启动MapReduce</h4>
<p>在Hadoop 2.x中，MapReduce Job不需要额外的daemon进程，在MapReduce Application Master启动的时候会自动启动JobTracker和TaskTracker进程，Job结束的时候会自动被关闭。</p>

<h4 id="distributedshell">1.5.4 运行一个DistributedShell的例子</h4>
<p>运行一个Hadoop自带的例子，名称为<code>DistributedShell</code>，可以同时在多台机器上运行shell命令。</p>

<pre><code>$ hadoop jar $HADOOP_PREFIX/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar org.apache.hadoop.yarn.applications.distributedshell.Client --jar $HADOOP_PREFIX/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar --shell_command date --num_containers 2
</code></pre>

<p>运行完成后，看看倒数第三行，有类似与<code>application_1391783685869_0001</code>的字符串，这是application ID。查看该application的每个container的输出，执行下面的命令，</p>

<pre><code>$ grep "" $HADOOP_PREFIX/logs/userlogs/&lt;APPLICATION ID&gt;/**/stdout
</code></pre>

<h4 id="wordcount">1.5.5 运行wordcount</h4>

<pre><code>$ cd $HADOOP_PREFIX
$ hdfs dfs -put ./etc/hadoop/ input
$ hadoop jar $HADOOP_PREFIX/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount input output
$ hdfs dfs -lsr output
$ hdfs dfs -cat output/part-r-00000
</code></pre>

<p>结束后，关闭 Hadoop:</p>

<pre><code>$ stop-dfs.sh
$ stop-yarn.sh
</code></pre>

<h2 id="fully-distributed-mode">2 分布式模式(Fully-Distributed Mode)</h2>

<h3 id="section-5">2.1 准备3台机器</h3>
<p>如果你已经有了三台机器，这一步可以省略。</p>

<p>如果没有，则可以用VMware Workstation 或 VirtualBox创建3台虚拟机。首先用vmware workstation 新建一台CentOS 6.5，装好操作系统，选择 Basic Server，安装JDK，参考我的另一篇博客，<a href="http://www.yanjiuyanjiu.com/blog/20120423/">安装和配置CentOS服务器的详细步骤</a>。安装好后然后用<strong>浅拷贝</strong><code>Create a linked clone</code> 克隆出2台，这样有了3台虚拟机。启动3台机器，假设IP分别为<code>192.168.1.131, 192.168.1.132, 192.168.1.133</code>, 131做为NameNode,JobTracker和SecondaryNameNode，身兼3个角色，这3个角色应该放到3台不同的机器上，这里为了简化，用一台机器来做3个角色；132和133为 slave。假设三台机器上的用户名是<code>hadoop</code>，也可以用其他用户名，但必须三台机器都相同。</p>

<h4 id="section-6">2.1.1 关闭防火墙</h4>
<p>临时关闭防火墙</p>

<pre><code>$ sudo service iptables stop
</code></pre>

<p>下次开机后，防火墙还是会启动。</p>

<p>永久关闭防火墙</p>

<pre><code>$ sudo chkconfig iptables off
</code></pre>

<p>由于这几台虚拟机是开发机，不是生产环境，因此不必考虑安全性，可以永久关闭防火墙，还能给开发阶段带来很多便利。</p>

<h4 id="hostname">2.1.2 修改hostname</h4>
<p>如果集群中的每一台机器事先已经有了hostname，则这一步可以跳过。</p>

<p>这一步看起来貌似不必要，其实是必须的，否则最后运行wordcount等例子时，会出现“Too many fetch-failures”。因为HDFS用hostname而不是IP，来相互之间进行通信（见后面的注意1）。</p>

<p>在CentOS上修改hostname，包含两个步骤(假设将hostname1改为hostname2，参考<a href="http://www.ichiayi.com/wiki/tech/linux_hostname">这里</a>，但不需要第一步)：</p>

<ol>
  <li>将 <code>/etc/sysconfig/network</code> 內的 HOSTNAME 改成 yourhostname</li>
  <li>用<code>hostname</code>命令，临时修改机器名， <code>sudo hostname yourhostname</code></li>
</ol>

<p>用<code>exit</code>命令退出shell，再次登录，命令提示字符串就会变成<code>[username@yourhostname ~]$</code>。</p>

<p>用上述方法，将131改名为master，132改名为slave01，133改名为slave02。</p>

<p><strong>注意</strong>，对于有的Ubuntu/Debia 系统，会把本机的hostname解析成 127.0.1.1，例如：</p>

<pre><code>127.0.0.1       localhost
127.0.1.1       master
</code></pre>

<p>将第二行改为(参考<a href="http://wiki.ubuntu.org.cn/%E5%88%A9%E7%94%A8Cloudera%E5%AE%9E%E7%8E%B0Hadoop">利用Cloudera实现Hadoop</a>)</p>

<pre><code>127.0.0.1       master
</code></pre>

<h4 id="etchosts">2.1.3 修改所有机器的<code>/etc/hosts</code>文件</h4>
<p>在所有机器的<code>/etc/hosts</code>文件中，添加所有hostname对应的IP，一般在一台机器上设置好，然后scp到所有机器。例如</p>

<pre><code>192.168.1.131 master
192.168.1.132 slave01
192.168.1.133 slave02
</code></pre>

<h3 id="master-master">2.2 配置 master 无密码登陆到所有机器（包括master自己登陆自己）</h3>
<p>参考我的另一篇博客，<a href="http://www.yanjiuyanjiu.com/blog/20120102/">SSH无密码登录的配置</a></p>

<h3 id="hadoop">2.3 把Hadoop压缩包上传到所有机器，并解压</h3>
<p>将 hadoop-1.2.1-bin.tar.gz 上传到所有机器，然后解压。<strong>注意，所有机器的hadoop路径必须一致，因为master会登陆到slave上执行命令，master认为slave的hadoop路径与自己一样。</strong></p>

<p>下面开始配置，配置好了后，把<code>./etc/hadoop</code>目录scp到所有其他机器。</p>

<h3 id="section-7">2.4 修改配置文件</h3>
<p>在第1节的基础上，增加下列修改。</p>

<h4 id="namenode">2.4.1 指定NameNode</h4>
<p>在core-site.xml中，<code>fs.defaultFS</code>要改为运行NameNode的那台机器的hostname，不再是localhost。</p>

<pre><code>&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;fs.defaultFS&lt;/name&gt;
    &lt;value&gt;hdfs://master&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<h4 id="resourcemanager">2.4.2 指定ResourceManager</h4>
<p>在yarn-site.xml中增加，</p>

<pre><code>&lt;property&gt;
   &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
   &lt;value&gt;master&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<h4 id="slavenodemanager">2.4.3 添加Slave，即NodeManager</h4>
<p>在 <code>etc/hadoop/slaves</code>中添加，</p>

<pre><code>slave01
slave02
</code></pre>

<h4 id="hadooptmpdir">2.4.4 设置 hadoop.tmp.dir</h4>
<p>在core-site.xml里添加：</p>

<pre><code>&lt;property&gt;
  &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
  &lt;value&gt;/home/hadoop/local/var/hadoop/tmp/hadoop-${user.name}&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<h4 id="mapred-sitexml">2.4.4 修改mapred-site.xml</h4>
<p>添加如下内容：</p>

<pre><code>&lt;property&gt;
    &lt;name&gt;mapreduce.jobtracker.staging.root.dir&lt;/name&gt;
    &lt;value&gt;/user&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>这是为以后的多用户支持做准备。</p>

<h4 id="pid">2.4.4 设置pid文件的存放位置</h4>
<p>在hadoop-env.sh中添加</p>

<pre><code>export HADOOP_MAPRED_PID_DIR=/home/hadoop/local/var/hadoop/pids
</code></pre>

<p>在 mapred-env.sh中添加</p>

<pre><code>export HADOOP_PID_DIR=/home/hadoop/local/var/hadoop/pids
</code></pre>

<h4 id="dfsreplicationslave">2.4.5 将dfs.replication设置为slave的个数</h4>
<p>我们这里有2台slave，就设置为2。在hdfs-site.xml里添加：</p>

<pre><code>&lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;2&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<h4 id="slaves">2.4.6 将配置文件拷贝到所有slaves</h4>

<pre><code>$ cd $HADOOP_PREFIX/etc/hadoop
$ scp hadoop-env.sh mapred-env.sh core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml slaves hadoop@slave01:$HADOOP_PREFIX/etc/hadoop
$ scp hadoop-env.sh mapred-env.sh core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml slaves hadoop@slave02:$HADOOP_PREFIX/etc/hadoop
</code></pre>

<h3 id="section-8">2.5 设置环境变量</h3>
<p>在所有机器上添加环境变量，与第1.3节相同。</p>

<h3 id="hadoop-1">2.6 启动 hadoop</h3>

<h4 id="hdfs-2">2.6.1 启动HDFS</h4>
<p>在NameNode这个机器（在这里是master）上执行下列命令，</p>

<pre><code>#只需一次，下次启动不再需要格式化，只需 start-dfs.sh
$ hdfs namenode -format
$ start-dfs.sh
</code></pre>

<h4 id="yarn-2">2.6.2 启动Yarn</h4>
<p>在ResourceManager这台机器（在这里仍然是master）上执行，</p>

<pre><code>$ start-yarn.sh
</code></pre>

<h4 id="mapreduce-2">2.6.3 启动MapReduce</h4>
<p>在Hadoop 2.x中，MapReduce Job不需要额外的daemon进程，在Job开始的时候，NodeManager会启动一个MapReduce Application Master（相当与一个精简的JobTracker），Job结束的时候自动被关闭。</p>

<h4 id="section-9">2.6.4 检查是否启动成功</h4>
<p>用<code>jps</code>查看java进程。</p>

<p>在master上，应该有三个进程，NameNode, SecondaryNameNode, ResourceManger；在每台slave上，应该有两个进程，DataNode, NodeManager。</p>

<h4 id="web-ui">2.6.5 Web UI</h4>
<p>可以用浏览器打开NameNode, ResourceManager和各个NodeManager的web界面，</p>

<ul>
  <li>NameNode web UI, <a href="http://master:50070/">http://master:50070/</a></li>
  <li>ResourceManager web UI, <a href="http://master:8088/">http://master:8088/</a></li>
  <li>NodeManager web UI, <a href="http://slave01:8042">http://slave01:8042</a></li>
</ul>

<p>还可以启动JobHistory Server，能够通过Web页面查看集群的历史Job，执行如下命令：</p>

<pre><code>mr-jobhistory-daemon.sh start historyserver
</code></pre>

<p>默认使用19888端口，通过访问<a href="http://master:19888/">http://master:19888/</a>查看历史信息。</p>

<p>终止JobHistory Server，执行如下命令：</p>

<pre><code>mr-jobhistory-daemon.sh stop historyserver
</code></pre>

<h3 id="wordcount-1">2.8 运行wordcount</h3>
<p>将输入数据拷贝到HDFS中:</p>

<pre><code>$ cd $HADOOP_PREFIX
$ hdfs dfs -put ./etc/hadoop input
</code></pre>

<p>这一步会报错，”No such file or directory”, 用<code>hdfs dfs -ls /</code>查看，是空的，难怪了。我们需要手动建立”/user/hadoop”目录，</p>

<pre><code>$ hdfs dfs -mkdir /user/hadoop
</code></pre>

<p>再上传文件，就可以了。</p>

<p>运行WordCount:</p>

<pre><code>$ hadoop jar $HADOOP_PREFIX/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount input output
</code></pre>

<p>查看结果：</p>

<pre><code>$ hdfs dfs -lsr output
$ hdfs dfs -cat output/part-r-00000
</code></pre>

<p>如果能看到结果，说明这个例子运行成功。</p>

<h3 id="hadoop-2">2.9 停止 hadoop集群</h3>
<p>在master上执行：</p>

<pre><code>$ stop-yarn.sh
$ stop-hdfs.sh
</code></pre>

<h2 id="section-10">4. 排除错误</h2>
<p>本文已经尽可能的把步骤详细列出来了，但是我相信大部分人不会一次成功。这时候，查找错误就很重要了。查找错误最重要的手段是查看hadoop的日志，一般在logs目录下。把错误消息复制粘贴到google，搜索一下，慢慢找错误。</p>

<h2 id="section-11">参考资料</h2>

<ol>
  <li><a href="http://hadoop.apache.org/docs/r2.2.0/hadoop-project-dist/hadoop-common/core-default.xml">core-default</a>, <a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml">hdfs-default</a>, <a href="http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-common/yarn-default.xml">yarn-default</a>, <a href="http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml">mapred-default</a></li>
  <li><a href="http://dongxicheng.org/mapreduce-nextgen/hadoop-yarn-install/">Hadoop YARN安装部署初探</a></li>
  <li><a href="http://www.alexjf.net/blog/distributed-systems/hadoop-yarn-installation-definitive-guide">Hadoop YARN Installation: The definitive guide</a></li>
  <li><a href="http://codesfusion.blogspot.com/2013/10/setup-hadoop-2x-220-on-ubuntu.html">Setup newest Hadoop 2.x (2.2.0) on Ubuntu</a></li>
  <li><a href="http://shiyanjun.cn/archives/561.html">Hadoop-2.2.0集群安装配置实践</a></li>
  <li><a href="http://dongxicheng.org/mapreduce-nextgen/hadoop-yarn-configurations-resourcemanager-nodemanager/">Hadoop YARN配置参数剖析(1)—RM与NM相关参数</a></li>
</ol>

<h2 id="section-12">相关文章</h2>

<ol>
  <li><a href="http://www.yanjiuyanjiu.com/blog/20140202">在CentOS上安装Hadoop集群</a></li>
  <li><a href="http://www.yanjiuyanjiu.com/blog/20120103/">在Ubuntu上安装Hadoop</a></li>
</ol>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">soulmachine</span></span>

      








  


<time datetime="2014-02-05T12:39:00+08:00" pubdate data-updated="true">Feb 5<span>th</span>, 2014</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/hadoop/'>Hadoop</a>
  
</span>


    </p>
    
      <div class="sharing">
  <!-- AddThis Button BEGIN -->
  <div class="addthis_toolbox addthis_default_style addthis_32x32_style">
    <a class="addthis_button_sinaweibo"></a>
    <a class="addthis_button_facebook"></a>
    <a class="addthis_button_twitter"></a>
    <a class="addthis_button_google_plusone_share"></a>
    <a class="addthis_button_delicious"></a>
    <a class="addthis_button_digg"></a>
    <a class="addthis_button_reddit"></a>
    <a class="addthis_button_compact"></a><a class="addthis_counter addthis_bubble_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=undefined"></script>
  <!-- AddThis Button END -->
  
  
  
</div>

    
    
	
    <section>
      <div id="duoshuo_thread" aria-live="polite"><!-- Duoshuo Comment BEGIN -->
<div class="ds-thread" data-thread-key="/blog/20140205" data-title="在CentOS上安装Hadoop 2.x 集群"></div>
<script type="text/javascript">
var duoshuoQuery = {short_name:"yanjiuyanjiu"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = 'http://static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		|| document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
</script>
<!-- Duoshuo Comment END --></div>
    </section>
    
    <ul class="pager">
      
      <li class="previous"><a class="basic-alignment left"
        href="/blog/20140204" title="Previous Post:
        把Nutch爬虫部署到Hadoop集群上">&laquo; 把Nutch爬虫部署到Hadoop集群上</a></li>
      
      <li><a href="/blog/archives">Blog Archives</a></li>
      
      <li class="next"><a class="basic-alignment right" href="/blog/20140206"
        title="Next Post: Hadoop多用户的配置(Hadoop 2.x)">Hadoop多用户的配置(Hadoop 2.x)
        &raquo;</a></li>
      
    </ul>
  </footer>
</article>

<aside class="sidebar-nav span3">
  
    <section>
  <h2>公告</h2>
  <p>独学而无友，则孤陋而寡闻，我每周在清华举办机器学习读书会，欢迎大家前来交流切磋。</p>
  <p>详情请见<a href="http://q.weibo.com/1644133">读书会微博群</a></p>
</section>
<section>
  <h2>分类目录</h2>
    <ul id="category-list"><li><a href='/blog/categories/algorithm/'>Algorithm (1)</a></li><li><a href='/blog/categories/devops/'>DevOps (8)</a></li><li><a href='/blog/categories/docker/'>Docker (3)</a></li><li><a href='/blog/categories/hadoop/'>Hadoop (8)</a></li><li><a href='/blog/categories/language/'>Language (3)</a></li><li><a href='/blog/categories/machine-learning/'>Machine-Learning (5)</a></li><li><a href='/blog/categories/search-engine/'>Search-Engine (5)</a></li><li><a href='/blog/categories/spark/'>Spark (6)</a></li><li><a href='/blog/categories/tools/'>Tools (11)</a></li></ul>
</section>
<section>
  <h2>友情链接</h2>
  <ul>
    <li>
      <a href="http://yewen.us/" title="大学同学，ACM高手，曾在百度，现在人人网">笨狗随手留下</a>
    </li>
	<li>
      <a href="http://blog.liancheng.info/" title="网易，百度，技术高手">连城</a>
    </li>
    <li>
      <a href="http://www.rational.so/" title="系统方向的清华博士">阎栋</a>
    </li>
	<li>
      <a href="http://www.parallellabs.com/" title="冠诚，IBM研究院研究员">并行实验室</a>
    </li>
	<li>
      <a href="http://blog.javachen.com/" title="">JavaChen</a>
    </li>
	<li>
      <a href="http://shenfeng.me/" title="http-kit, clojure">沈峰</a>
    </li>
	<li>
      <a href="http://www.lihaipeng.info/" title="百度商业产品高级研发工程师">李海鹏</a>
    </li>
	<li>
      <a href="http://www.chioka.in/" title="Google工程师">Eric</a>
    </li>
    <li>
      <a href="http://blog.csdn.net/lgnlgn" title="好朋友，曾在赶集网，现在老家的猫扑">梁兄的技术博客</a>
    </li>
    <li>
      <a href="http://www.doesbetter.com/" title="机器学习，北邮">王孝舒的博客</a>
    </li>
    <li>
      <a href="http://www.foreverlee.net/" title="机器学习，中科院计算所">ForeverLee</a>
    </li>
  </ul>
</section>




<section>
  <h2>最新文章</h2>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/20140220">编写Nutch插件</a>
      </li>
    
      <li class="post">
        <a href="/blog/20140214">CentOS上编译 Hadoop 2.2.0</a>
      </li>
    
      <li class="post">
        <a href="/blog/20140208">在CentOS上安装HBase 0.96</a>
      </li>
    
      <li class="post">
        <a href="/blog/20140207">在CentOS上安装ZooKeeper集群</a>
      </li>
    
      <li class="post">
        <a href="/blog/20140206">Hadoop多用户的配置(Hadoop 2.x)</a>
      </li>
    
  </ul>
</section><section>
<h2>最新评论</h2>
<ul class="ds-recent-comments" data-num-items="5" data-show-avatars="1" data-show-time="1" data-show-title="1" data-show-admin="0" data-excerpt-length="32"></ul>

</section>

  
</aside>


    </div>
  </div>
  <footer role="contentinfo" class="page-footer"><!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
<p>
  Copyright &copy; 2014 - soulmachine -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  











</body>
</html>
