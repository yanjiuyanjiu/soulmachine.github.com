
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>在CentOS上安装Hadoop - 研究研究</title>
  <meta name="author" content="soulmachine">

  
  <meta name="description" content="一个关于机器学习的技术博客">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://www.yanjiuyanjiu.com/blog/20130612">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/bootstrap/bootstrap.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/bootstrap/responsive.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/syntax/syntax.css" media="screen, projection" rel="stylesheet" type="text/css">
  <style type="text/css">
    body {
      padding-bottom: 40px;
    }
    h1 {
      margin-bottom: 15px;
    }
    img {
      max-width: 100%;
    }
    .sharing, .meta, .pager {
      margin: 20px 0px 20px 0px;
    }
    .page-footer p {
      text-align: center;
    }
  </style>
  <script src="/javascripts/libs/jquery.js"></script>
  <script src="/javascripts/libs/modernizr-2.0.js"></script>
  <script src="/javascripts/libs/bootstrap.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="研究研究" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<!-- <link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css"> -->
<!-- <link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css"> -->

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-7583537-4']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <nav role="navigation"><div class="navbar navbar-inverse">
  <div class="navbar-inner">
    <div class="container">
      <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </a>

      <a class="brand" href="/">研究研究</a>

      <div class="nav-collapse">
        <ul class="nav">
  <li><a href="/">Home</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about/">About</a></li>
  <li><a href="/notes/">读书笔记</a></li>
</ul>


        <ul class="nav pull-right" data-subscription="rss">
          <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
          
        </ul>

        
          <form class="pull-right navbar-search" action="http://google.com/search" method="get">
            <fieldset role="search">
              <input type="hidden" name="q" value="site:www.yanjiuyanjiu.com" />
              <input class="search-query" type="text" name="q" results="0" placeholder="Search"/>
            </fieldset>
          </form>
        
      </div>
    </div>
  </div>
</div>
</nav>
  <div class="container">
    <div class="row-fluid">
      
<article class="hentry span9" role="article">

  
  <header class="page-header">
    
      <h1 class="entry-title">在CentOS上安装Hadoop</h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-06-12T12:39:00+08:00" pubdate data-updated="true">Jun 12<span>th</span>, 2013</time>
        
		
         | <a href="#duoshuo_thread">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><p>Ubuntu上安装，请参考我的另一篇博客，<a href="http://www.yanjiuyanjiu.com/blog/20120103/">在Ubuntu上安装Hadoop</a>。</p>

<p><strong>环境</strong>：CentOS 6.4, JDK 1.7, Hadoop 1.1.2</p>

<h2 id="vmware-workstation-">1. 用vmware workstation 创建三台虚拟机</h2>
<p>首先用vmware workstation 新建一台CentOS 6.4，装好操作系统，选择 Basic Server，安装JDK，参考我的另一篇博客，<a href="http://www.yanjiuyanjiu.com/blog/20120423/">安装和配置CentOS服务器的详细步骤</a>。安装好后然后用浅拷贝<code>Create a linked clone</code> 克隆出两台作为slave，这样有了三台虚拟机。启动三台机器，假设IP分别为<code>192.168.1.131, 192.168.1.132, 192.168.1.133</code>, 131做为master 和 SecondaryNameNode, 身兼两职， 132和133为 slaves。</p>

<h2 id="section">2 关闭防火墙</h2>
<p>临时关闭防火墙</p>

<pre><code>$ sudo service iptables stop 下次开机后，防火墙还是会启动。
</code></pre>

<p>永久关闭防火墙</p>

<pre><code>$ sudo chkconfig iptables off 由于这几台虚拟机是开发机，不是生产环境，因此不必考虑安全性，可以永久关闭防火墙，还能给开发阶段带来很多便利。
</code></pre>

<h2 id="hostname">3. 修改hostname</h2>
<p>这一步看起来貌似不必要，其实是必须的，否则最后运行wordcount等例子时，会出现“Too many fetch-failures”。因为HDFS用hostname而不是IP，来相互之间进行通信（见后面的注意1）。</p>

<p>在CentOS上修改hostname，包含两个步骤(假设将hostname1改为hostname2，参考<a href="http://www.ichiayi.com/wiki/tech/linux_hostname">这里</a>，但不需要第一步)：</p>

<ol>
  <li>将 <code>/etc/sysconfig/network</code> 內的 HOSTNAME 改成 hostname2</li>
  <li>用<code>hostname</code>命令，临时修改机器名， <code>sudo hostname hostname2</code></li>
</ol>

<p>用<code>exit</code>命令退出shell，再次登录，命令提示字符串就会变成<code>[dev@hostname2 ~]$</code>。</p>

<p>用上述方法，将131改名为master，132改名为slave01，133改名为slave02。</p>

<p>在三台机器的/etc/hosts文件中，添加以下三行内容</p>

<pre><code>192.168.1.131 master
192.168.1.132 slave01
192.168.1.133 slave02
</code></pre>

<h2 id="section-1">4. 本地模式和伪分布式模式</h2>

<p>为了能顺利安装成功，我们先练习在单台机器上安装Hadoop。在单台机器上，可以配置成本地模式(local mode)和伪分布式模式(Pseudo-Distributed Mode)，参考官方文档<a href="http://hadoop.apache.org/docs/r1.1.2/single_node_setup.html">Single Node Setup</a>。</p>

<p>将 hadoop-1.1.2-bin.tar.gz 上传到三台机器的 home目录下，然后解压。</p>

<h3 id="confhadoop-envsh-javahome">4.1 编辑 conf/hadoop-env.sh，设置 JAVA_HOME</h3>

<pre><code>cd hadoop-1.1.2
vim conf/hadoop-env.sh
</code></pre>

<p>注释掉第8行的JAVA_HOME，设置正确的JDK位置</p>

<pre><code>export JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.19.x86_64
</code></pre>

<h3 id="section-2">4.2 测试本地模式是否正常</h3>
<p>默认情况下，Hadoop就被配置为本地模式，现在就可以开始测试一下。</p>

<pre><code>$ mkdir input 
$ cp conf/*.xml input 
$ bin/hadoop jar hadoop-examples-*.jar grep input output 'dfs[a-z.]+' 
$ cat output/*
</code></pre>

<p>可以看到正常的结果，说明本地模式运行成功了，下面开始配置伪分布式模式。</p>

<!-- more -->

<h3 id="ssh">4.3 配置SSH无密码登陆本机</h3>

<pre><code>$ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
</code></pre>

<p>修改sshd的配置文件(需要root权限)</p>

<pre><code>$ sudo vim /etc/ssh/sshd_config
</code></pre>

<p>找到以下三行，并去掉注释符”#“</p>

<pre><code>RSAAuthentication yes
PubkeyAuthentication yes
AuthorizedKeysFile      .ssh/authorized_keys
</code></pre>

<p>修改了配置文件需要重启sshd服务</p>

<pre><code>sudo service sshd restart
</code></pre>

<p>修改 <code>authorized_keys</code> 文件的权限，否则ssh登陆的时候还是需要密码。权限的设置非常重要,因为不安全的设置,会让你不能使用RSA功能，参考 <a href="http://www.cnblogs.com/xia520pi/archive/2012/05/16/2504132.html">http://www.cnblogs.com/xia520pi/archive/2012/05/16/2504132.html</a></p>

<pre><code>$ chmod 600 ~/.ssh/authorized_keys
</code></pre>

<h3 id="section-3">4.4 修改配置文件</h3>
<p>conf/core-site.xml:</p>

<pre><code>&lt;configuration&gt;
     &lt;property&gt;
         &lt;name&gt;fs.default.name&lt;/name&gt;
         &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
     &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>conf/hdfs-site.xml:</p>

<pre><code>&lt;configuration&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.replication&lt;/name&gt;
         &lt;value&gt;1&lt;/value&gt;
     &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>conf/mapred-site.xml:</p>

<pre><code>&lt;configuration&gt;
     &lt;property&gt;
         &lt;name&gt;mapred.job.tracker&lt;/name&gt;
         &lt;value&gt;localhost:9001&lt;/value&gt;
     &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<h3 id="hadoop">4.5 启动Hadoop，测试伪分布式模式</h3>

<p>格式化namenode</p>

<pre><code>$ bin/hadoop namenode -format
</code></pre>

<p>启动 Hadoop 后台进程</p>

<pre><code>$ bin/start-all.sh
</code></pre>

<p>现在可以用浏览器打开NameNode和JobTracker的web界面了。<br />
NameNode - <a href="http://localhost:50070/">http://localhost:50070/</a><br />
JobTracker - <a href="http://localhost:50030/">http://localhost:50030/</a></p>

<p>将输入数据拷贝到分布式文件系统中:</p>

<pre><code>$ bin/hadoop fs -put conf input
</code></pre>

<p>如果这时出现 <code>SafeModeException</code> 异常，不用担心，等待几分钟即可。因为hadoop刚刚启动时，会进入安全模式进行自检。</p>

<p>运行 Hadoop 自带的例子:</p>

<pre><code>$ bin/hadoop jar hadoop-examples-*.jar grep input output 'dfs[a-z.]+'
</code></pre>

<p>查看输出文件:</p>

<pre><code>$ bin/hadoop fs -cat output/*
</code></pre>

<p>当你做完了后，关闭 Hadoop:</p>

<pre><code>$ bin/stop-all.sh
</code></pre>

<h2 id="section-4">5. 分布式模式</h2>
<p>如果有多台机器，就可以把Hadoop 配置成分布式模式(或称为集群模式)。参考官方文档<a href="http://hadoop.apache.org/docs/r1.1.2/cluster_setup.html">Cluster Setup</a>.</p>

<h2 id="master-master">5.1 配置 master 无密码登陆到所有机器（<strong>包括master自己登陆自己</strong>）</h2>
<p>首先在两台slave上修改sshd的配置文件，然后重启sshd服务。</p>

<pre><code>$ sudo vim /etc/ssh/sshd_config  找到以下三行，并去掉注释符”#“

RSAAuthentication yes
PubkeyAuthentication yes
AuthorizedKeysFile      .ssh/authorized_keys
</code></pre>

<p>修改了配置文件需要重启sshd服务</p>

<pre><code>$ sudo service sshd restart
</code></pre>

<p>在两台slaves机器上新建 ~/.ssh 目录</p>

<pre><code>$ mkdir ~/.ssh
</code></pre>

<p>在master机器上执行： </p>

<pre><code>#生成公钥
$ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
</code></pre>

<p>把公钥拷贝到所有机器上（包括自己）</p>

<pre><code># 拷贝到自己
$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
# 拷贝到两台slaves机器上
$ scp ~/.ssh/id_rsa.pub dev@192.168.1.132:~/.ssh/authorized_keys
$ scp ~/.ssh/id_rsa.pub dev@192.168.1.133:~/.ssh/authorized_keys
</code></pre>

<p>修改 .ssh目录和authorized_keys 文件的权限</p>

<pre><code>#在三台机器上执行以下命令
$ chmod 600 ~/.ssh/authorized_keys
# 在两台 slaves 上执行以下命令
$ chmod 700 ~/.ssh
</code></pre>

<p>测试，看看 master 是否可以无密码登陆两台slave</p>

<pre><code>#在 master执行
$ ssh 192.168.1.132
$ exit
$ ssh 192.168.1.133
$ exit 如果不需要密码，则说明配置成功了。
</code></pre>

<p>如果登陆不上，试试先关闭两台slaves的防火墙</p>

<pre><code>$ sudo service iptables stop
</code></pre>

<h3 id="section-5">5.2 修改6个配置文件</h3>
<p>在 master 上修改配置文件。</p>

<p>编辑 conf/hadoop-env.sh，设置 JAVA_HOME。</p>

<p>在master上编辑 conf/hadoop-env.sh，注释掉第8行的JAVA_HOME，设置正确的JDK位置，确保集群中所有机器的JDK都安装在这个位置，这样待会儿后面可以用scp命令把master的6个配置文件(hadoop-env.sh, core-site.xml, hdfs-site.xml, mapred-site.xml, masters, slaves)拷贝到所有slaves机器上，这样其他机器就不用重复进行配置了。</p>

<p>conf/masters:</p>

<pre><code>master
</code></pre>

<p>conf/slaves:</p>

<pre><code>slave01
slave02
</code></pre>

<p>这两个配置文件的作用是，指定131作为master, 132和133为 slaves。</p>

<p>conf/core-site.xml:</p>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.default.name&lt;/name&gt;
        &lt;value&gt;hdfs://master:9000&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>conf/hdfs-site.xml:</p>

<pre><code>&lt;configuration&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.name.dir&lt;/name&gt;
         &lt;value&gt;/home/dev/hdfs/name&lt;/value&gt;
     &lt;/property&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.data.dir&lt;/name&gt;
         &lt;value&gt;/home/dev/hdfs/data&lt;/value&gt;
     &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>要在master创建 /home/dev/hdfs/name 目录，在 slaves上创建 /home/dev/hdfs/data 目录，并<code>chmod g-w /home/dev/hdfs/data</code>（权限不对的话datanode无法启动）。</p>

<p>conf/mapred-site.xml:</p>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapred.job.tracker&lt;/name&gt;
        &lt;value&gt;master:9001&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<h3 id="slaves">5.3 将配置文件拷贝到所有slaves</h3>

<pre><code>$ cd ~/hadoop-1.1.2/conf/
$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves dev@192.168.1.132:~/hadoop-1.1.2/conf/
$ scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves dev@192.168.1.133:~/hadoop-1.1.2/conf/
</code></pre>

<h3 id="hadoophomehadoophomebinpath">5.4 设置环境变量HADOOP_HOME，并将<code>$HADOOP_HOME/bin</code>加入PATH</h3>
<p>所有机器都要设置环境变量HADOOP_HOME，并将<code>$HADOOP_HOME/bin</code>加入PATH，因为master登陆到slave后，要执行<code>$HADOOP_HOME/bin</code> 下的一些命令。</p>

<pre><code>$ vim ~/.bash_profile
</code></pre>

<p>添加以下内容：</p>

<pre><code>export HADOOP_HOME=$HOME/hadoop-1.1.2
export PATH=$PATH:$HOME/bin:$HADOOP_HOME/bin::$HADOOP_HOME/sbin
export CLASSPATH=$CLASSPATH:$HADOOP_HOME/hadoop-core-1.1.2.jar
</code></pre>

<p>source一下，使得环境变量立刻生效</p>

<pre><code>$ source ~/.bash_profile
</code></pre>

<h3 id="hadoop-1">5.5 运行 hadoop</h3>
<p>在master上执行以下命令，启动hadoop</p>

<pre><code>#只需一次，下次启动不再需要格式化，只需 start-all.sh
$ hadoop  namenode -format
$ start-all.sh
</code></pre>

<h3 id="section-6">5.6 检查是否启动成功</h3>

<p>在master上执行：</p>

<pre><code>$ jps

2615 NameNode
2767 JobTracker
2874 Jps
</code></pre>

<p>在一台slave上执行：</p>

<pre><code>$ jps

3415 DataNode
3582 TaskTracker
3499 SecondaryNameNode
3619 Jps
</code></pre>

<p>在另一台slave上执行：</p>

<pre><code>$ jps

3741 Jps
3618 DataNode
3702 TaskTracker
</code></pre>

<p>可见进程都启动起来了，说明hadoop运行成功。</p>

<h3 id="wordcount">5.7 运行wordcount例子，进一步测试是否安装成功</h3>
<p>将输入数据拷贝到分布式文件系统中:</p>

<pre><code>$ cd $HADOOP_HOME
$ hadoop fs -put conf input
</code></pre>

<p>运行 Hadoop 自带的例子:</p>

<pre><code>$ hadoop jar hadoop-examples-*.jar wordcount input output
</code></pre>

<p>查看输出文件:</p>

<pre><code>$ hadoop s -ls output
$ hadoop fs -cat output/part-r-00000
</code></pre>

<p>如果能看到结果，说明这个例子运行成功。</p>

<h3 id="hadoop-2">5.8 停止 hadoop集群</h3>
<p>在master上执行：</p>

<pre><code>$ stop-all.sh
</code></pre>

<h2 id="section-7">6. 排除错误</h2>
<p>本文已经尽可能的把步骤详细列出来了，但是我相信大部分人不会一次成功。这时候，查找错误就很重要了。查找错误最重要的手段是查看hadoop的日志，一般在logs目录下。把错误消息复制粘贴到google，搜索一下，慢慢找错误。</p>

<h2 id="section-8">注意</h2>
<ol>
  <li>所有配置文件只能用hostname，不能用IP。两年前我不懂，还为此<a href="http://stackoverflow.com/questions/8702637/hadoop-conf-fs-default-name-cant-be-setted-ipport-format-directly">在stackoverflow上发了帖子</a>。hadoop会反向解析hostname，即使是用了IP，也会使用hostname 来启动TaskTracker。参考<a href="http://stackoverflow.com/questions/15230946/hdfs-lan-ip-address-hostname-resolution">hdfs LAN ip address hostname resolution</a>，<a href="http://www.makenotes.net/?p=337004">hadoop入门经验总结- 杨贵堂的博客</a>，<a href="http://51mst.iteye.com/blog/1152439">hadoop集群配置</a>。</li>
  <li>如果在第 3.7步有问题，可以<code>stop-all.sh</code>, 然后<code>hadoop  namenode -format</code>，反复多试几次，一般可以成功。如果不习惯，多看看 logs目录下的日志文件，把错误消息复制粘贴到google，搜索答案。</li>
  <li>在第2.5步骤，如果出现 <code>SafeModeException</code> 异常，不用担心，等待几分钟即可。因为hadoop刚刚启动时，会进入安全模式进行自检，这需要花点时间。</li>
</ol>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">soulmachine</span></span>

      








  


<time datetime="2013-06-12T12:39:00+08:00" pubdate data-updated="true">Jun 12<span>th</span>, 2013</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/hadoop/'>hadoop</a>
  
</span>


    </p>
    
      <div class="sharing">
  <!-- AddThis Button BEGIN -->
  <div class="addthis_toolbox addthis_default_style addthis_32x32_style">
    <a class="addthis_button_sinaweibo"></a>
    <a class="addthis_button_facebook"></a>
    <a class="addthis_button_twitter"></a>
    <a class="addthis_button_google_plusone_share"></a>
    <a class="addthis_button_delicious"></a>
    <a class="addthis_button_digg"></a>
    <a class="addthis_button_reddit"></a>
    <a class="addthis_button_compact"></a><a class="addthis_counter addthis_bubble_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=undefined"></script>
  <!-- AddThis Button END -->
  
  
  
</div>

    
    
	
    <section>
      <div id="duoshuo_thread" aria-live="polite"><!-- Duoshuo Comment BEGIN -->
<div class="ds-thread" data-thread-key="/blog/20130612" data-title="在CentOS上安装Hadoop"></div>
<script type="text/javascript">
var duoshuoQuery = {short_name:"yanjiuyanjiu"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = 'http://static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		|| document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
</script>
<!-- Duoshuo Comment END --></div>
    </section>
    
    <ul class="pager">
      
      <li class="previous"><a class="basic-alignment left"
        href="/blog/20130611" title="Previous Post:
        使用Scala IDE 阅读spark源码 -- 将sbt项目转化为eclipse项目">&laquo; 使用Scala IDE 阅读spark源码 -- 将sbt项目转化为eclipse项目</a></li>
      
      <li><a href="/blog/archives">Blog Archives</a></li>
      
      <li class="next"><a class="basic-alignment right" href="/blog/20130617"
        title="Next Post: Installing Spark on CentOS">Installing Spark on CentOS
        &raquo;</a></li>
      
    </ul>
  </footer>
</article>

<aside class="sidebar-nav span3">
  
    <section>
  <h2>公告</h2>
  <p>独学而无友，则孤陋而寡闻，我每周在清华举办机器学习读书会，欢迎大家前来交流切磋。</p>
  <p>详情请见<a href="http://q.weibo.com/1644133">读书会微博群</a></p>
</section>
<section>
  <h2>分类目录</h2>
    <ul id="category-list"><li><a href='/blog/categories/algorithm/'>algorithm (1)</a></li><li><a href='/blog/categories/hadoop/'>hadoop (2)</a></li><li><a href='/blog/categories/language/'>language (2)</a></li><li><a href='/blog/categories/machine-learning/'>machine-learning (4)</a></li><li><a href='/blog/categories/spark/'>spark (2)</a></li><li><a href='/blog/categories/tools/'>tools (10)</a></li></ul>
</section>
<section>
  <h2>友情链接</h2>
  <ul>
    <li>
      <a href="http://yewen.us/" title="大学同学，ACM高手，曾在百度，现在人人网">笨狗随手留下</a>
    </li>
	<li>
      <a href="http://blog.liancheng.info/" title="网易，百度，技术高手">连城</a>
    </li>
	<li>
      <a href="http://www.parallellabs.com/" title="冠诚，IBM研究院研究员">并行实验室</a>
    </li>
	<li>
      <a href="http://shenfeng.me/" title="http-kit, clojure">沈峰</a>
    </li>
	<li>
      <a href="http://www.lihaipeng.info/" title="百度商业产品高级研发工程师">李海鹏</a>
    </li>
    <li>
      <a href="http://blog.csdn.net/lgnlgn" title="好朋友，曾在赶集网，现在老家的猫扑">梁兄的技术博客</a>
    </li>
    <li>
      <a href="http://www.doesbetter.com/" title="机器学习，北邮">王孝舒的博客</a>
    </li>
    <li>
      <a href="http://www.foreverlee.net/" title="机器学习，中科院计算所">ForeverLee</a>
    </li>
  </ul>
</section>




<section>
  <h2>最新文章</h2>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/20130617">Installing Spark on CentOS</a>
      </li>
    
      <li class="post">
        <a href="/blog/20130612">在CentOS上安装Hadoop</a>
      </li>
    
      <li class="post">
        <a href="/blog/20130611">使用Scala IDE 阅读spark源码 -- 将sbt项目转化为eclipse项目</a>
      </li>
    
      <li class="post">
        <a href="/blog/20130412">LaTeX的各种发行版和编辑器的比较</a>
      </li>
    
      <li class="post">
        <a href="/blog/20130402">我的Octopress配置</a>
      </li>
    
  </ul>
</section><section>
<h2>最新评论</h2>
<ul class="ds-recent-comments" data-num-items="5" data-show-avatars="1" data-show-time="1" data-show-title="1" data-show-admin="0" data-excerpt-length="32"></ul>

</section>

  
</aside>


    </div>
  </div>
  <footer role="contentinfo" class="page-footer"><!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
<p>
  Copyright &copy; 2013 - soulmachine -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  











</body>
</html>
